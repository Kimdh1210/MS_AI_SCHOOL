{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\std\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\anaconda3\\envs\\std\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "c:\\anaconda3\\envs\\std\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=True, download=False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.5,),(0.5,))\n",
    "                                          ])),batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, download=False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.5,),(0.5,))\n",
    "                                          ])),batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의 \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # 784 = 28 x 28 \n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # 맨 마지막 부분에는 해당 클래스 개수 \n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 호출\n",
    "model = MLP()\n",
    "\n",
    "# 손실함수 및 최적화 알고리즘 정의 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss : 2.209\n",
      "[1,   200] loss : 1.895\n",
      "[1,   300] loss : 1.370\n",
      "[1,   400] loss : 0.961\n",
      "[1,   500] loss : 0.728\n",
      "[1,   600] loss : 0.624\n",
      "[1,   700] loss : 0.533\n",
      "[1,   800] loss : 0.477\n",
      "[1,   900] loss : 0.451\n",
      "[2,   100] loss : 0.424\n",
      "[2,   200] loss : 0.405\n",
      "[2,   300] loss : 0.398\n",
      "[2,   400] loss : 0.373\n",
      "[2,   500] loss : 0.371\n",
      "[2,   600] loss : 0.373\n",
      "[2,   700] loss : 0.349\n",
      "[2,   800] loss : 0.341\n",
      "[2,   900] loss : 0.351\n",
      "[3,   100] loss : 0.333\n",
      "[3,   200] loss : 0.335\n",
      "[3,   300] loss : 0.317\n",
      "[3,   400] loss : 0.303\n",
      "[3,   500] loss : 0.320\n",
      "[3,   600] loss : 0.320\n",
      "[3,   700] loss : 0.306\n",
      "[3,   800] loss : 0.308\n",
      "[3,   900] loss : 0.302\n",
      "[4,   100] loss : 0.281\n",
      "[4,   200] loss : 0.278\n",
      "[4,   300] loss : 0.284\n",
      "[4,   400] loss : 0.308\n",
      "[4,   500] loss : 0.296\n",
      "[4,   600] loss : 0.263\n",
      "[4,   700] loss : 0.272\n",
      "[4,   800] loss : 0.272\n",
      "[4,   900] loss : 0.293\n",
      "[5,   100] loss : 0.261\n",
      "[5,   200] loss : 0.266\n",
      "[5,   300] loss : 0.241\n",
      "[5,   400] loss : 0.268\n",
      "[5,   500] loss : 0.251\n",
      "[5,   600] loss : 0.254\n",
      "[5,   700] loss : 0.257\n",
      "[5,   800] loss : 0.265\n",
      "[5,   900] loss : 0.247\n",
      "[6,   100] loss : 0.245\n",
      "[6,   200] loss : 0.246\n",
      "[6,   300] loss : 0.244\n",
      "[6,   400] loss : 0.227\n",
      "[6,   500] loss : 0.239\n",
      "[6,   600] loss : 0.221\n",
      "[6,   700] loss : 0.225\n",
      "[6,   800] loss : 0.232\n",
      "[6,   900] loss : 0.243\n",
      "[7,   100] loss : 0.218\n",
      "[7,   200] loss : 0.227\n",
      "[7,   300] loss : 0.230\n",
      "[7,   400] loss : 0.218\n",
      "[7,   500] loss : 0.231\n",
      "[7,   600] loss : 0.224\n",
      "[7,   700] loss : 0.199\n",
      "[7,   800] loss : 0.197\n",
      "[7,   900] loss : 0.207\n",
      "[8,   100] loss : 0.211\n",
      "[8,   200] loss : 0.208\n",
      "[8,   300] loss : 0.193\n",
      "[8,   400] loss : 0.183\n",
      "[8,   500] loss : 0.210\n",
      "[8,   600] loss : 0.194\n",
      "[8,   700] loss : 0.201\n",
      "[8,   800] loss : 0.189\n",
      "[8,   900] loss : 0.197\n",
      "[9,   100] loss : 0.187\n",
      "[9,   200] loss : 0.188\n",
      "[9,   300] loss : 0.199\n",
      "[9,   400] loss : 0.186\n",
      "[9,   500] loss : 0.186\n",
      "[9,   600] loss : 0.175\n",
      "[9,   700] loss : 0.181\n",
      "[9,   800] loss : 0.167\n",
      "[9,   900] loss : 0.175\n",
      "[10,   100] loss : 0.181\n",
      "[10,   200] loss : 0.182\n",
      "[10,   300] loss : 0.164\n",
      "[10,   400] loss : 0.160\n",
      "[10,   500] loss : 0.178\n",
      "[10,   600] loss : 0.169\n",
      "[10,   700] loss : 0.167\n",
      "[10,   800] loss : 0.162\n",
      "[10,   900] loss : 0.163\n",
      "[11,   100] loss : 0.161\n",
      "[11,   200] loss : 0.169\n",
      "[11,   300] loss : 0.166\n",
      "[11,   400] loss : 0.157\n",
      "[11,   500] loss : 0.157\n",
      "[11,   600] loss : 0.164\n",
      "[11,   700] loss : 0.153\n",
      "[11,   800] loss : 0.149\n",
      "[11,   900] loss : 0.145\n",
      "[12,   100] loss : 0.147\n",
      "[12,   200] loss : 0.146\n",
      "[12,   300] loss : 0.158\n",
      "[12,   400] loss : 0.157\n",
      "[12,   500] loss : 0.146\n",
      "[12,   600] loss : 0.142\n",
      "[12,   700] loss : 0.138\n",
      "[12,   800] loss : 0.150\n",
      "[12,   900] loss : 0.146\n",
      "[13,   100] loss : 0.138\n",
      "[13,   200] loss : 0.136\n",
      "[13,   300] loss : 0.140\n",
      "[13,   400] loss : 0.132\n",
      "[13,   500] loss : 0.130\n",
      "[13,   600] loss : 0.142\n",
      "[13,   700] loss : 0.134\n",
      "[13,   800] loss : 0.152\n",
      "[13,   900] loss : 0.136\n",
      "[14,   100] loss : 0.133\n",
      "[14,   200] loss : 0.138\n",
      "[14,   300] loss : 0.132\n",
      "[14,   400] loss : 0.131\n",
      "[14,   500] loss : 0.127\n",
      "[14,   600] loss : 0.128\n",
      "[14,   700] loss : 0.134\n",
      "[14,   800] loss : 0.124\n",
      "[14,   900] loss : 0.124\n",
      "[15,   100] loss : 0.122\n",
      "[15,   200] loss : 0.116\n",
      "[15,   300] loss : 0.130\n",
      "[15,   400] loss : 0.114\n",
      "[15,   500] loss : 0.124\n",
      "[15,   600] loss : 0.133\n",
      "[15,   700] loss : 0.120\n",
      "[15,   800] loss : 0.113\n",
      "[15,   900] loss : 0.127\n",
      "[16,   100] loss : 0.111\n",
      "[16,   200] loss : 0.111\n",
      "[16,   300] loss : 0.117\n",
      "[16,   400] loss : 0.114\n",
      "[16,   500] loss : 0.117\n",
      "[16,   600] loss : 0.116\n",
      "[16,   700] loss : 0.115\n",
      "[16,   800] loss : 0.121\n",
      "[16,   900] loss : 0.111\n",
      "[17,   100] loss : 0.107\n",
      "[17,   200] loss : 0.106\n",
      "[17,   300] loss : 0.117\n",
      "[17,   400] loss : 0.097\n",
      "[17,   500] loss : 0.115\n",
      "[17,   600] loss : 0.104\n",
      "[17,   700] loss : 0.116\n",
      "[17,   800] loss : 0.105\n",
      "[17,   900] loss : 0.108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Python\\인공신경망 이론\\다층 퍼셉트론.ipynb 셀 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%9D%B4%EB%A1%A0/%EB%8B%A4%EC%B8%B5%20%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m) : \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%9D%B4%EB%A1%A0/%EB%8B%A4%EC%B8%B5%20%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Python/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%9D%B4%EB%A1%A0/%EB%8B%A4%EC%B8%B5%20%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i,(inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m) : \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%9D%B4%EB%A1%A0/%EB%8B%A4%EC%B8%B5%20%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%9D%B4%EB%A1%A0/%EB%8B%A4%EC%B8%B5%20%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\std\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:917\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    913\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    916\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n\u001b[1;32m--> 917\u001b[0m     tensor \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    919\u001b[0m dtype \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    920\u001b[0m mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(mean, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train loop \n",
    "for epoch in range(50) : \n",
    "    running_loss = 0.0\n",
    "    for i,(inputs, labels) in enumerate(train_loader, 0) : \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99 : \n",
    "            print('[%d, %5d] loss : %.3f'%(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "std",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
